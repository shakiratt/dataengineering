{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df359d27-28ae-4678-982e-8a399c26ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.9.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01647890-d542-42fe-a560-f6b9d3391412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "16a4593f-b8d9-472e-8d9e-deafaaea5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "90115460-9220-462b-8715-1cba5ba48a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'addressLine1': '843 E 30th St', 'city': 'Baltimore', 'state': 'MD', 'zipCode': '21218', 'formattedAddress': '843 E 30th St, Baltimore, MD 21218', 'county': 'Baltimore City', 'features': {}, 'id': '843-E-30th-St,-Baltimore,-MD-21218', 'longitude': -76.606186, 'latitude': 39.323861}, {'addressLine1': '822 San Juan Pl', 'city': 'San Diego', 'state': 'CA', 'zipCode': '92109', 'formattedAddress': '822 San Juan Pl, Apt 4, San Diego, CA 92109', 'addressLine2': 'Apt 4', 'bedrooms': 2, 'squareFootage': 1669, 'yearBuilt': 1984, 'county': 'San Diego', 'assessorID': '423-606-13-04', 'legalDescription': 'TR 1651 BLK 160*US 4 PER DOC85-028354&UND INT IN LOTS I&J', 'subdivision': 'MISSION BEACH', 'zoning': 'R-1:SINGLE FAM-RES', 'bathrooms': 2, 'lotSize': 4778, 'propertyType': 'Condo', 'ownerOccupied': False, 'features': {'architectureType': 'Condo / Apartment', 'garage': True, 'garageSpaces': 2, 'garageType': 'Garage', 'unitCount': 1}, 'taxAssessment': {'2022': {'value': 310439, 'land': 146663, 'improvements': 163776}, '2023': {'value': 316647, 'land': 149596, 'improvements': 167051}}, 'propertyTaxes': {'2022': {'total': 3816}, '2023': {'total': 3921}}, 'owner': {'names': ['RC PARTNERSHIP'], 'mailingAddress': {'id': '2950-Bayside-Walk,-San-Diego,-CA-92109', 'formattedAddress': '2950 Bayside Walk, San Diego, CA 92109', 'addressLine1': '2950 Bayside Walk', 'city': 'San Diego', 'state': 'CA', 'zipCode': '92109'}, 'type': 'Organization'}, 'id': '822-San-Juan-Pl,-Apt-4,-San-Diego,-CA-92109', 'longitude': -117.25183, 'latitude': 32.780446}, {'addressLine1': '4763 Rosebud Cv', 'city': 'Southaven', 'state': 'MS', 'zipCode': '38672', 'formattedAddress': '4763 Rosebud Cv, Southaven, MS 38672', 'assessorID': '2-07-2-10-13-0-00104-00', 'county': 'Desoto', 'legalDescription': 'ROSEBURY, SEC. B LOT 104', 'ownerOccupied': True, 'squareFootage': 1910, 'subdivision': 'ROSEBURY SEC B', 'yearBuilt': 2015, 'lotSize': 12556, 'propertyType': 'Single Family', 'lastSaleDate': '2018-08-28T00:00:00.000Z', 'bedrooms': 3, 'zoning': 'PUD', 'features': {'exteriorType': 'Brick Veneer', 'foundationType': 'Slab / Mat / Raft', 'roofType': 'Shingle', 'roomCount': 8}, 'taxAssessment': {'2017': {'value': 13991, 'land': 3500, 'improvements': 10491}, '2019': {'value': 14232, 'land': 3500, 'improvements': 10732}, '2022': {'value': 15165, 'land': 3500, 'improvements': 11665}, '2023': {'value': 15165}}, 'propertyTaxes': {'2017': {'total': 1693}, '2019': {'total': 1717}, '2022': {'total': 1849}, '2023': {'total': 1895}}, 'owner': {'names': ['A Laeshia A Adams'], 'mailingAddress': {'id': '4763-Rosebud-Cv,-Southaven,-MS-38672', 'formattedAddress': '4763 Rosebud Cv, Southaven, MS 38672', 'addressLine1': '4763 Rosebud Cv', 'city': 'Southaven', 'state': 'MS', 'zipCode': '38672'}, 'type': 'Individual'}, 'id': '4763-Rosebud-Cv,-Southaven,-MS-38672', 'longitude': -89.932892, 'latitude': 34.929832}, {'addressLine1': '4935 Guernsey Rd', 'city': 'Milton', 'state': 'FL', 'zipCode': '32571', 'formattedAddress': '4935 Guernsey Rd, Milton, FL 32571', 'bedrooms': 3, 'squareFootage': 2076, 'yearBuilt': 1999, 'features': {'cooling': True, 'coolingType': 'Central', 'exteriorType': 'Brick', 'fireplace': True, 'floorCount': 1, 'foundationType': 'Masonry', 'garage': True, 'garageType': 'Garage', 'heating': True, 'heatingType': 'Forced Air', 'roofType': 'Asphalt', 'unitCount': 1}, 'county': 'Santa Rosa', 'assessorID': '08-1N-29-0000-01108-0000', 'legalDescription': \"COM SW CORN OF NW4 OF NE4 OF SECTION 8 TOWNSHIP 1 NORTH RANGE 29 WEST TH S 88*38'13E 525 FT TH N01*44' 11E 503 FT TO POB TH\", 'subdivision': 'WEST', 'zoning': 'AG-RR', 'ownerOccupied': True, 'bathrooms': 2, 'lotSize': 54450, 'propertyType': 'Single Family', 'taxAssessment': {'2023': {'value': 170879}}, 'propertyTaxes': {'2023': {'total': 1719}}, 'lastSalePrice': 200000, 'lastSaleDate': '2019-12-27T00:00:00.000Z', 'owner': {'names': ['Steven R Lusk'], 'mailingAddress': {'id': '4935-Guernsey-Rd,-Pace,-FL-32571', 'formattedAddress': '4935 Guernsey Rd, Pace, FL 32571', 'addressLine1': '4935 Guernsey Rd', 'city': 'Pace', 'state': 'FL', 'zipCode': '32571'}}, 'id': '4935-Guernsey-Rd,-Milton,-FL-32571', 'longitude': -87.171307, 'latitude': 30.616804}, {'addressLine1': '805 Sandra Ln', 'city': 'Jonesboro', 'state': 'AR', 'zipCode': '72405', 'formattedAddress': '805 Sandra Ln, Jonesboro, AR 72405', 'assessorID': '01-144104-11900', 'county': 'Craighead', 'legalDescription': 'WYATTWOOD SECOND ADDITIONPT NW SE', 'ownerOccupied': True, 'squareFootage': 2172, 'subdivision': 'WYATTWOOD SECOND ADD', 'bathrooms': 2, 'lotSize': 13068, 'propertyType': 'Single Family', 'features': {'cooling': True, 'coolingType': 'Central', 'exteriorType': 'Brick Veneer', 'floorCount': 1, 'foundationType': 'Slab / Mat / Raft', 'garage': True, 'garageSpaces': 2, 'garageType': 'Attached', 'heating': True, 'heatingType': 'Central', 'roofType': 'Asphalt'}, 'taxAssessment': {'2019': {'value': 35650, 'land': 5000, 'improvements': 30650}, '2023': {'value': 39537, 'land': 5000, 'improvements': 34537}}, 'propertyTaxes': {'2019': {'total': 1338}, '2023': {'total': 1900}}, 'lastSalePrice': 335000, 'lastSaleDate': '2022-07-29T00:00:00.000Z', 'owner': {'names': ['WILLIAM S MCNEIL'], 'mailingAddress': {'id': '4804-Highway,-232-E,-England,-AR-72046', 'addressLine1': '4804 Highway', 'city': 'England', 'state': 'AR', 'zipCode': '72046', 'addressLine2': '232 E'}}, 'id': '805-Sandra-Ln,-Jonesboro,-AR-72405', 'longitude': -90.647081, 'latitude': 35.852262}, {'bathrooms': 2, 'bedrooms': 2, 'squareFootage': 1134, 'county': 'Miami-Dade', 'propertyType': 'Apartment', 'addressLine1': '1080 Brickell Ave', 'addressLine2': 'Unit 2309', 'city': 'Miami', 'state': 'FL', 'zipCode': '33131', 'formattedAddress': '1080 Brickell Ave, Unit 2309, Miami, FL 33131', 'yearBuilt': 2016, 'lastSaleDate': '2016-10-11T00:00:00.000Z', 'lastSalePrice': 646900, 'assessorID': '01-4139-127-2980', 'legalDescription': 'THE BOND (1080 BRICKELL) CONDO UNIT 2309 UNDIV 0.3609% INT IN COMMON ELEMENTS OFF REC 28808-2358', 'subdivision': 'BOND 1080 BRICKELL', 'zoning': '6407:HIGH DENS MIX USE', 'ownerOccupied': False, 'features': {'architectureType': 'Condo / Apartment'}, 'taxAssessment': {'2023': {'value': 641400}}, 'propertyTaxes': {'2023': {'total': 11647}}, 'owner': {'names': ['SISSI USA CORP'], 'type': 'Organization', 'mailingAddress': {'id': '150-Se-2nd-Ave,-STE-1408,-Miami,-FL-33131', 'formattedAddress': '150 Se 2nd Ave, STE 1408, Miami, FL 33131', 'addressLine1': '150 Se 2nd Ave', 'city': 'Miami', 'state': 'FL', 'zipCode': '33131', 'addressLine2': 'STE 1408'}}, 'id': '1080-Brickell-Ave,-Unit-2309,-Miami,-FL-33131', 'longitude': -80.192659, 'latitude': 25.76284}, {'addressLine1': '25730 Player Dr', 'city': 'Valencia', 'state': 'CA', 'zipCode': '91355', 'formattedAddress': '25730 Player Dr, Unit S7, Valencia, CA 91355', 'addressLine2': 'Unit S7', 'assessorID': '2851-008-175', 'bedrooms': 3, 'county': 'Los Angeles', 'legalDescription': '*TR=35769 CONDOMINIUM*UNIT 175', 'ownerOccupied': True, 'squareFootage': 1296, 'subdivision': 'VALENCIA AT LAKESHORE', 'yearBuilt': 1971, 'zoning': 'SCUR3', 'bathrooms': 2, 'lotSize': 676060, 'propertyType': 'Condo', 'lastSalePrice': 395000, 'lastSaleDate': '2020-03-13T00:00:00.000Z', 'features': {'architectureType': 'Condo / Apartment', 'cooling': True, 'coolingType': 'Commercial', 'heating': True, 'heatingType': 'Central', 'unitCount': 1}, 'taxAssessment': {'2019': {'value': 185987, 'land': 57032, 'improvements': 128955}, '2023': {'value': 415212, 'land': 235252, 'improvements': 179960}}, 'propertyTaxes': {'2019': {'total': 2748}, '2023': {'total': 5662}}, 'owner': {'names': ['Lori Whitbeck', 'Gerald I Brainum'], 'mailingAddress': {'id': '25730-Player-Dr,-UNIT-S7,-Santa-Clarita,-CA-91355', 'formattedAddress': '25730 Player Dr, UNIT S7, Santa Clarita, CA 91355', 'addressLine1': '25730 Player Dr', 'city': 'Santa Clarita', 'state': 'CA', 'zipCode': '91355', 'addressLine2': 'UNIT S7'}, 'type': 'Individual'}, 'id': '25730-Player-Dr,-Unit-S7,-Valencia,-CA-91355', 'longitude': -118.562076, 'latitude': 34.389298}, {'addressLine1': '937 Main St', 'city': 'Wakefield', 'state': 'MA', 'zipCode': '01880', 'formattedAddress': '937 Main St, Apt 5, Wakefield, MA 01880', 'addressLine2': 'Apt 5', 'county': 'Middlesex', 'features': {}, 'id': '937-Main-St,-Apt-5,-Wakefield,-MA-01880', 'longitude': -71.066357, 'latitude': 42.482558}, {'bathrooms': 1.5, 'bedrooms': 3, 'squareFootage': 1743, 'county': 'Catoosa', 'propertyType': 'Single Family', 'addressLine1': '250 Hickory Cir', 'city': 'Ringgold', 'state': 'GA', 'zipCode': '30736', 'formattedAddress': '250 Hickory Cir, Ringgold, GA 30736', 'lastSalePrice': 293400, 'lastSaleDate': '2024-07-12T00:00:00.000Z', 'lotSize': 27443, 'yearBuilt': 1966, 'features': {'cooling': True, 'coolingType': 'Central', 'exteriorType': 'Brick Veneer', 'fireplace': True, 'floorCount': 1, 'foundationType': 'OTHER', 'garage': True, 'garageType': 'Garage', 'heating': True, 'heatingType': 'Central', 'roofType': 'Composition Shingle', 'unitCount': 1}, 'assessorID': '0023B112', 'legalDescription': 'LOT 3 SCENIC HILLS', 'subdivision': 'SCENIC HILLS SUB', 'zoning': 'R-1', 'ownerOccupied': True, 'taxAssessment': {'2023': {'value': 69102, 'land': 14794, 'improvements': 54308}}, 'propertyTaxes': {'2023': {'total': 1547}}, 'owner': {'names': ['James Johnson'], 'mailingAddress': {'id': '250-Hickory-Cir,-Ringgold,-GA-30736', 'formattedAddress': '250 Hickory Cir, Ringgold, GA 30736', 'addressLine1': '250 Hickory Cir', 'city': 'Ringgold', 'state': 'GA', 'zipCode': '30736'}}, 'id': '250-Hickory-Cir,-Ringgold,-GA-30736', 'longitude': -85.157958, 'latitude': 34.921414}, {'bathrooms': 2, 'bedrooms': 2, 'squareFootage': 1341, 'county': 'Marion', 'propertyType': 'Single Family', 'addressLine1': '7947 Sw 89th Loop', 'city': 'Ocala', 'state': 'FL', 'zipCode': '34476', 'formattedAddress': '7947 Sw 89th Loop, Ocala, FL 34476', 'yearBuilt': 2020, 'assessorID': '3566-001-004', 'legalDescription': 'SEC 18 TWP 16 RGE 21', 'subdivision': 'CIRCLE SQUARE WOODS', 'zoning': 'PUD', 'ownerOccupied': False, 'lotSize': 5227, 'lastSalePrice': 119000, 'lastSaleDate': '2022-08-09T00:00:00.000Z', 'features': {'cooling': True, 'coolingType': 'Commercial', 'exteriorType': 'Stucco', 'floorCount': 1, 'foundationType': 'Slab / Mat / Raft', 'heating': True, 'heatingType': 'Central', 'roofType': 'Fiberglass', 'unitCount': 1, 'garage': True, 'garageType': 'Garage'}, 'taxAssessment': {'2022': {'value': 182904}, '2023': {'value': 230435, 'land': 13671, 'improvements': 216764}}, 'propertyTaxes': {'2022': {'total': 3018}, '2023': {'total': 3894}}, 'owner': {'names': ['LUCKY SIX FARMS LLC'], 'mailingAddress': {'id': '10578-Sw-98th-Pl,-Ocala,-FL-34481', 'formattedAddress': '10578 Sw 98th Pl, Ocala, FL 34481', 'addressLine1': '10578 Sw 98th Pl', 'city': 'Ocala', 'state': 'FL', 'zipCode': '34481'}, 'type': 'Organization'}, 'id': '7947-Sw-89th-Loop,-Ocala,-FL-34476', 'longitude': -82.250442, 'latitude': 29.093213}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://realty-mole-property-api.p.rapidapi.com/randomProperties\"\n",
    "\n",
    "querystring = {\"limit\":\"1000\"}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"bc68487461mshca1d2214a6e1c46p1c3c47jsn5f4df3a84144\",\n",
    "\t\"x-rapidapi-host\": \"realty-mole-property-api.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.json())\n",
    "\n",
    "\n",
    "data= response.json()\n",
    "\n",
    "#Saving into a file\n",
    "filename = \"PropertyRecords.json\"\n",
    "with open(filename,\"w\") as file:\n",
    "    json.dump(data,file,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0e22613f-c370-49c1-861b-2f2466524ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read into a dataframe\n",
    "\n",
    "Propertyrecord_df = pd.read_json('PropertyRecords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ef4f5390-496f-4f7d-9f60-b6f7d93c059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   addressLine1      10 non-null     object \n",
      " 1   city              10 non-null     object \n",
      " 2   state             10 non-null     object \n",
      " 3   zipCode           10 non-null     int64  \n",
      " 4   formattedAddress  10 non-null     object \n",
      " 5   county            10 non-null     object \n",
      " 6   features          10 non-null     object \n",
      " 7   id                10 non-null     object \n",
      " 8   longitude         10 non-null     float64\n",
      " 9   latitude          10 non-null     float64\n",
      " 10  addressLine2      4 non-null      object \n",
      " 11  bedrooms          7 non-null      float64\n",
      " 12  squareFootage     8 non-null      float64\n",
      " 13  yearBuilt         7 non-null      float64\n",
      " 14  assessorID        8 non-null      object \n",
      " 15  legalDescription  8 non-null      object \n",
      " 16  subdivision       8 non-null      object \n",
      " 17  zoning            7 non-null      object \n",
      " 18  bathrooms         7 non-null      float64\n",
      " 19  lotSize           7 non-null      float64\n",
      " 20  propertyType      8 non-null      object \n",
      " 21  ownerOccupied     8 non-null      float64\n",
      " 22  taxAssessment     8 non-null      object \n",
      " 23  propertyTaxes     8 non-null      object \n",
      " 24  owner             8 non-null      object \n",
      " 25  lastSaleDate      7 non-null      object \n",
      " 26  lastSalePrice     6 non-null      float64\n",
      "dtypes: float64(9), int64(1), object(17)\n",
      "memory usage: 2.2+ KB\n",
      "Index(['addressLine1', 'city', 'state', 'zipCode', 'formattedAddress',\n",
      "       'county', 'features', 'id', 'longitude', 'latitude', 'addressLine2',\n",
      "       'bedrooms', 'squareFootage', 'yearBuilt', 'assessorID',\n",
      "       'legalDescription', 'subdivision', 'zoning', 'bathrooms', 'lotSize',\n",
      "       'propertyType', 'ownerOccupied', 'taxAssessment', 'propertyTaxes',\n",
      "       'owner', 'lastSaleDate', 'lastSalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "Propertyrecord_df.info()\n",
    "print(Propertyrecord_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd968081-9f0e-4ac3-8f9e-efe1c9bb4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformational \n",
    "\n",
    "#Convert columns with dictionary into string\n",
    "import json\n",
    "\n",
    "Propertyrecord_df['features']=Propertyrecord_df ['features'].apply(json.dumps)\n",
    "\n",
    "#fill missing nd NA values\n",
    "Propertyrecord_df.fillna(\n",
    "    {\n",
    "        'bathrooms': 0,\n",
    "        'bedrooms': 0,\n",
    "        'squareFootage': 0, \n",
    "        'county': \"Not Available\", \n",
    "        'propertyType': \"unknown\",\n",
    "        'addressLine1': \"unknown\",\n",
    "        'city': \"unknown\", \n",
    "        'state': \"unknown\", \n",
    "        'zipCode': \"unknown\", \n",
    "        'formattedAddress': \"Not Available\",\n",
    "        'yearBuilt': 0, \n",
    "        'features': \"unknown\", \n",
    "        'assessorID': \"unknown\", \n",
    "        'legalDescription': \"Not Available\",\n",
    "        'subdivision': \"Not Available\", \n",
    "        'ownerOccupied': 0, \n",
    "        'lotSize': 0, \n",
    "        'taxAssessment': \"Not Available\",\n",
    "        'propertyTaxes': \"Not Available\", \n",
    "        'lastSaleDate': \"Not Available\", \n",
    "        'lastSalePrice': 0, \n",
    "        'owner': \"unknown\", \n",
    "        'id': \"unknown\",\n",
    "        'longitude': \"unknown\", \n",
    "        'latitude': \"unknown\", \n",
    "        'zoning': \"unknown\", \n",
    "        'addressLine2': \"Not Available\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "483b9708-7bbc-41eb-b138-d739545f5076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bathrooms         10 non-null     float64\n",
      " 1   bedrooms          10 non-null     float64\n",
      " 2   squareFootage     10 non-null     float64\n",
      " 3   county            10 non-null     object \n",
      " 4   propertyType      10 non-null     object \n",
      " 5   addressLine1      10 non-null     object \n",
      " 6   city              10 non-null     object \n",
      " 7   state             10 non-null     object \n",
      " 8   zipCode           10 non-null     int64  \n",
      " 9   formattedAddress  10 non-null     object \n",
      " 10  lotSize           10 non-null     float64\n",
      " 11  yearBuilt         10 non-null     float64\n",
      " 12  features          10 non-null     object \n",
      " 13  assessorID        10 non-null     object \n",
      " 14  legalDescription  10 non-null     object \n",
      " 15  subdivision       10 non-null     object \n",
      " 16  zoning            10 non-null     object \n",
      " 17  taxAssessment     10 non-null     object \n",
      " 18  propertyTaxes     10 non-null     object \n",
      " 19  lastSalePrice     10 non-null     float64\n",
      " 20  lastSaleDate      10 non-null     object \n",
      " 21  ownerOccupied     10 non-null     float64\n",
      " 22  owner             10 non-null     object \n",
      " 23  id                10 non-null     object \n",
      " 24  longitude         10 non-null     float64\n",
      " 25  latitude          10 non-null     float64\n",
      " 26  addressLine2      10 non-null     object \n",
      "dtypes: float64(9), int64(1), object(17)\n",
      "memory usage: 2.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Propertyrecord_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "07c87900-fa72-4322-a119-895a63e5954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the FACT Table\n",
    "fact_columns =['addressLine1','city', 'state','zipCode', 'formattedAddress',  'squareFootage', 'yearBuilt', 'bathrooms', 'bedrooms', 'lotSize', 'propertyType',\n",
    "                'longitude', 'latitude']\n",
    "\n",
    "fact_table = Propertyrecord_df[fact_columns]\n",
    "\n",
    "#Create Location Dimension\n",
    "Location_dim= Propertyrecord_df[['addressLine1','city', 'state','zipCode','county','longitude', 'latitude']].drop_duplicates().reset_index(drop=True)\n",
    "Location_dim.index.name= 'location_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7a82f556-3b82-42d3-9df2-075186b082f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastSalePrice</th>\n",
       "      <th>lastSaleDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-28T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2019-12-27T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335000.0</td>\n",
       "      <td>2022-07-29T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>646900.0</td>\n",
       "      <td>2016-10-11T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lastSalePrice              lastSaleDate\n",
       "sales_id                                         \n",
       "0                   NaN                       NaN\n",
       "1                   NaN  2018-08-28T00:00:00.000Z\n",
       "2              200000.0  2019-12-27T00:00:00.000Z\n",
       "3              335000.0  2022-07-29T00:00:00.000Z\n",
       "4              646900.0  2016-10-11T00:00:00.000Z"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Sales Dimension\n",
    "\n",
    "sales_dim = Propertyrecord_df[['lastSalePrice','lastSaleDate']].drop_duplicates().reset_index(drop=True)\n",
    "sales_dim.index.name= 'sales_id'\n",
    "sales_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "188d3bb3-4ae5-4ddc-8ab9-ebae9a5b7c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[257], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Create Property Features Dimension\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m features_dim \u001b[38;5;241m=\u001b[39m Propertyrecord_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpropertyType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzoning\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m features_dim\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_id\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m features_dim\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_dim.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6818\u001b[0m, in \u001b[0;36mDataFrame.drop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6815\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6816\u001b[0m ignore_index \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(ignore_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6818\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicated(subset, keep\u001b[38;5;241m=\u001b[39mkeep)]\n\u001b[0;32m   6819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[0;32m   6820\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[1;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(f, vals)))\n\u001b[0;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mfactorize(vals, size_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[0;32m    796\u001b[0m         values,\n\u001b[0;32m    797\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    798\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[0;32m    799\u001b[0m     )\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[0;32m    596\u001b[0m     values,\n\u001b[0;32m    597\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    598\u001b[0m     na_value\u001b[38;5;241m=\u001b[39mna_value,\n\u001b[0;32m    599\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    600\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    601\u001b[0m )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "#Create Property Features Dimension\n",
    "features_dim = Propertyrecord_df[['features', 'propertyType', 'zoning']].drop_duplicates().reset_index(drop=True)\n",
    "features_dim.index.name ='features_id'\n",
    "features_dim.to_csv('features_dim.csv')\n",
    "features_dim.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dabc1c42-6094-4350-a5f6-a9e1b35f8711",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Output to csv\n",
    "fact_table.to_csv('property_fact.csv', index=False)\n",
    "Location_dim.to_csv('Location_dimension.csv', index=True)\n",
    "sales_dim.to_csv('sales_dimension.csv', index=True)\n",
    "features_dim.to_csv('features_dimension.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0dd86273-1da1-416b-a554-7d199b74e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Loading Layer\n",
    "\n",
    "# develop a function to connect to pgadmin\n",
    "\n",
    "def get_db_connection():\n",
    "    connection = psycopg2.connect(\n",
    "        host= 'localhost',\n",
    "        database='postgres',\n",
    "        user='postgres',\n",
    "        password='shakirat12'\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "conn = get_db_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e029d033-a55c-4bde-b36d-b7d7787d332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating tables\n",
    "\n",
    "\n",
    "def create_tables():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    create_table_query='''CREATE SCHEMA IF NOT EXISTS zapbank;\n",
    "\n",
    "                            DROP TABLE IF EXISTS zapbank.fact_table;\n",
    "                            DROP TABLE IF EXISTS zapbank.location_dim;\n",
    "                            DROP TABLE IF EXISTS zapbank.sales_dim;\n",
    "                            DROP TABLE IF EXISTS zapbank.features_dim;\n",
    "\n",
    "                            CREATE TABLE zapbank.fact_table(\n",
    "                                addressline1 VARCHAR(255),\n",
    "                                city VARCHAR(100),\n",
    "                                state VARCHAR(50),\n",
    "                                zipCode INTEGER,\n",
    "                                formattedAddress VARCHAR(255),\n",
    "                                squareFootage FLOAT,\n",
    "                                yearBuilt FLOAT,\n",
    "                                bathrooms FLOAT,\n",
    "                                bedrooms FLOAT,\n",
    "                                lotSize FLOAT,\n",
    "                                propertyType VARCHAR(255),\n",
    "                                longitude FLOAT,\n",
    "                                latitude FLOAT\n",
    "                                );\n",
    "\n",
    "                                CREATE TABLE zapbank.location_dim(\n",
    "                                    location_id SERIAL PRIMARY KEY,\n",
    "                                    addressLine1 VARCHAR(255),\n",
    "                                    city VARCHAR(100),\n",
    "                                    state VARCHAR (50),\n",
    "                                    zipCode INTEGER,\n",
    "                                    county VARCHAR(100),\n",
    "                                    longitude FLOAT,\n",
    "                                    latitude FLOAT\n",
    "                                    );\n",
    "\n",
    "                                CREATE TABLE zapbank.sales_dim(\n",
    "                                   sales_id SERIAL PRIMARY KEY,\n",
    "                                   lastSalePrice FLOAT,\n",
    "                                   lastSaleDate DATE\n",
    "                                   );\n",
    "\n",
    "                                CREATE TABLE zapbank.features_dim(\n",
    "                                    features_id SERIAL PRIMARY KEY,\n",
    "                                    features TEXT,\n",
    "                                    propertyType VARCHAR(255),\n",
    "                                    zoning VARCHAR(255)\n",
    "                                     );'''\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "create_tables()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e2f4f7a4-6330-4efa-a483-0bcdc896fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a funcion to load csv data from a folder into the DB\n",
    "def load_data_from_csv_to_table(csv_path,table_name):\n",
    "    conn= get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path,'r',encoding='utf-8') as file:\n",
    "        reader=csv.reader(file)\n",
    "        next(reader) #Skip the header row\n",
    "        for row in reader:\n",
    "            placeholders = ', '.join(['%s']* len(row))\n",
    "            query = f\"INSERT INTO {table_name} VALUES ({placeholders});\"\n",
    "            cursor.execute(query,row)\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f0a4bcf-0360-4a61-b54d-4547aa233494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fact table\n",
    "fact_csv_path = r'C:\\Users\\HP\\Documents\\Data Engineering Projects\\property_fact.csv'\n",
    "load_data_from_csv_to_table(fact_csv_path, 'zapbank.fact_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de8de237-8368-46e8-af9c-4ffec2dc7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Location dimension table\n",
    "location_csv_path = r'C:\\Users\\HP\\Documents\\Data Engineering Projects\\Location_dimension.csv'\n",
    "load_data_from_csv_to_table(location_csv_path, 'zapbank.location_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7ccebdf6-7121-4a7b-a6cc-73991e615822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for features dimension table\n",
    "features_csv_path = r'C:\\Users\\HP\\Documents\\Data Engineering Projects\\features_dimension.csv'\n",
    "load_data_from_csv_to_table(features_csv_path, 'zapbank.features_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8048dcd-7e5a-40ad-9246-ec14ae784f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c18634a7-7c54-423a-8c31-a4b4f6d003da",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Create a New funcion to load csv data for sales  from a folder into the DB\n",
    "def load_data_from_csv_to_sales_table(csv_path,table_name):\n",
    "    conn= get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path,'r',encoding='utf-8') as file:\n",
    "        reader=csv.reader(file)\n",
    "        next(reader) #Skip the header row\n",
    "        for row in reader:\n",
    "            #convert empty strings (or Not available) in date column to None (NULL in sql)\n",
    "            row=[\n",
    "              None if (cell == '' or cell =='Not Available') and col_name == 'lastSaleDate'\n",
    "                 else cell for cell, col_name in zip(row, sales_dim_columns)]\n",
    "        # Prepare query placeholders and execute the insert statement\n",
    "        \n",
    "        placeholders = ', '.join(['%s'] * len(row))\n",
    "        query = f\"INSERT INTO {table_name} VALUES ({placeholders});\"\n",
    "        cursor.execute(query, row)\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "   \n",
    "\n",
    "#define the columns names in sales_dim table\n",
    "sales_dim_columns = ['sales_id','lastSalePrice', 'lastSaleDate']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "441b3385-a18b-4343-8a3c-8edcf48626f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "def load_data_from_csv_to_sales_table(csv_path, table_name):\n",
    "    \"\"\"\n",
    "    Load sales data from CSV to database with proper data type handling and error checking.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get database connection\n",
    "        conn = get_db_connection()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Read the CSV file using pandas\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(\"Original CSV Data:\")\n",
    "        print(df)\n",
    "        \n",
    "        # Data type conversions\n",
    "        if 'lastSalePrice' in df.columns:\n",
    "            # Convert to float, replacing any non-numeric values with None\n",
    "            df['lastSalePrice'] = pd.to_numeric(df['lastSalePrice'], errors='coerce')\n",
    "        \n",
    "        if 'lastSaleDate' in df.columns:\n",
    "            # Replace empty strings or 'Not Available' with None\n",
    "            df['lastSaleDate'] = df['lastSaleDate'].replace(['', 'Not Available'], None)\n",
    "            # Convert to datetime, invalid parsing becomes None\n",
    "            df['lastSaleDate'] = pd.to_datetime(df['lastSaleDate'], errors='coerce')\n",
    "            # Convert timezone-aware timestamps to timezone-naive\n",
    "            df['lastSaleDate'] = df['lastSaleDate'].dt.tz_localize(None)\n",
    "\n",
    "        print(df)\n",
    "        # Iterate over each row and insert into the database\n",
    "        successful_inserts = 0\n",
    "        failed_inserts = 0\n",
    "        db_columns = list(df.columns)\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                print(row)\n",
    "                # Convert row to list and handle None values\n",
    "                row_data = [None if pd.isna(val) else val for val in row]\n",
    "                \n",
    "                # Prepare the insert statement\n",
    "                placeholders = ', '.join(['%s'] * len(row_data))\n",
    "                query = f\"INSERT INTO {table_name} ({', '.join(db_columns)}) VALUES ({placeholders});\"\n",
    "                \n",
    "                print(f\"\\nAttempting insert for row {index + 1}:\")\n",
    "                print(f\"Query: {query}\")\n",
    "                print(f\"Data: {row_data}\")\n",
    "                \n",
    "                cursor.execute(query, row_data)\n",
    "                successful_inserts += 1\n",
    "                \n",
    "            except Error as e:\n",
    "                failed_inserts += 1\n",
    "                print(f\"\\nError inserting row {index + 1}:\")\n",
    "                print(f\"Data: {row_data}\")\n",
    "                print(f\"Error: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "        \n",
    "        print(f\"\\nInsert Summary:\")\n",
    "        print(f\"Successful inserts: {successful_inserts}\")\n",
    "        print(f\"Failed inserts: {failed_inserts}\")\n",
    "        \n",
    "    except Error as e:\n",
    "        print(f\"Database error: {str(e)}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"General error: {str(e)}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d704aff9-00b2-417e-b9b6-060cd87997aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CSV Data:\n",
      "   lastSalePrice              lastSaleDate\n",
      "0       783991.0  2013-04-29T00:00:00.000Z\n",
      "1            0.0  2021-07-13T00:00:00.000Z\n",
      "2            0.0             Not Available\n",
      "3       629000.0  2016-10-12T00:00:00.000Z\n",
      "4       536005.0  2018-09-28T00:00:00.000Z\n",
      "   lastSalePrice lastSaleDate\n",
      "0       783991.0   2013-04-29\n",
      "1            0.0   2021-07-13\n",
      "2            0.0          NaT\n",
      "3       629000.0   2016-10-12\n",
      "4       536005.0   2018-09-28\n",
      "lastSalePrice               783991.0\n",
      "lastSaleDate     2013-04-29 00:00:00\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Attempting insert for row 1:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [783991.0, Timestamp('2013-04-29 00:00:00')]\n",
      "lastSalePrice                    0.0\n",
      "lastSaleDate     2021-07-13 00:00:00\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Attempting insert for row 2:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [0.0, Timestamp('2021-07-13 00:00:00')]\n",
      "lastSalePrice    0.0\n",
      "lastSaleDate     NaT\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Attempting insert for row 3:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [0.0, None]\n",
      "lastSalePrice               629000.0\n",
      "lastSaleDate     2016-10-12 00:00:00\n",
      "Name: 3, dtype: object\n",
      "\n",
      "Attempting insert for row 4:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [629000.0, Timestamp('2016-10-12 00:00:00')]\n",
      "lastSalePrice               536005.0\n",
      "lastSaleDate     2018-09-28 00:00:00\n",
      "Name: 4, dtype: object\n",
      "\n",
      "Attempting insert for row 5:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [536005.0, Timestamp('2018-09-28 00:00:00')]\n",
      "\n",
      "Insert Summary:\n",
      "Successful inserts: 5\n",
      "Failed inserts: 0\n"
     ]
    }
   ],
   "source": [
    "# Then load the data\n",
    "load_data_from_csv_to_sales_table(sales_csv_path, 'zapbank.sales_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b934bbe7-bdb1-4583-863f-9eafd8893e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CSV Data:\n",
      "   lastSalePrice              lastSaleDate\n",
      "0       783991.0  2013-04-29T00:00:00.000Z\n",
      "1            0.0  2021-07-13T00:00:00.000Z\n",
      "2            0.0             Not Available\n",
      "3       629000.0  2016-10-12T00:00:00.000Z\n",
      "4       536005.0  2018-09-28T00:00:00.000Z\n",
      "   lastSalePrice lastSaleDate\n",
      "0       783991.0   2013-04-29\n",
      "1            0.0   2021-07-13\n",
      "2            0.0          NaT\n",
      "3       629000.0   2016-10-12\n",
      "4       536005.0   2018-09-28\n",
      "lastSalePrice               783991.0\n",
      "lastSaleDate     2013-04-29 00:00:00\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Attempting insert for row 1:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [783991.0, Timestamp('2013-04-29 00:00:00')]\n",
      "lastSalePrice                    0.0\n",
      "lastSaleDate     2021-07-13 00:00:00\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Attempting insert for row 2:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [0.0, Timestamp('2021-07-13 00:00:00')]\n",
      "lastSalePrice    0.0\n",
      "lastSaleDate     NaT\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Attempting insert for row 3:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [0.0, None]\n",
      "lastSalePrice               629000.0\n",
      "lastSaleDate     2016-10-12 00:00:00\n",
      "Name: 3, dtype: object\n",
      "\n",
      "Attempting insert for row 4:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [629000.0, Timestamp('2016-10-12 00:00:00')]\n",
      "lastSalePrice               536005.0\n",
      "lastSaleDate     2018-09-28 00:00:00\n",
      "Name: 4, dtype: object\n",
      "\n",
      "Attempting insert for row 5:\n",
      "Query: INSERT INTO zapbank.sales_dim (lastSalePrice, lastSaleDate) VALUES (%s, %s);\n",
      "Data: [536005.0, Timestamp('2018-09-28 00:00:00')]\n",
      "\n",
      "Insert Summary:\n",
      "Successful inserts: 5\n",
      "Failed inserts: 0\n"
     ]
    }
   ],
   "source": [
    "# for sales dimension table\n",
    "sales_csv_path = r'C:\\Users\\HP\\Documents\\Data Engineering Projects\\sales_dimension.csv'\n",
    "load_data_from_csv_to_sales_table(sales_csv_path, 'zapbank.sales_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "af55f62e-cf6b-4403-89ea-3d195d25eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv_to_sales_table(csv_path, table_name):\n",
    "    import csv\n",
    "\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Define column names\n",
    "    sales_dim_columns = ['sales_id', 'lastSalePrice', 'lastSaleDate']\n",
    "\n",
    "    with open(csv_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "\n",
    "        for row in reader:\n",
    "            # Convert values to match table schema\n",
    "            row = [\n",
    "                int(cell) if col_name == 'sales_id' and cell.isdigit() else  # Convert sales_id to integer\n",
    "                float(cell) if col_name == 'lastSalePrice' and cell.replace('.', '', 1).isdigit() else  # Convert lastSalePrice to float\n",
    "                None if (cell == '' or cell == 'Not Available') and col_name == 'lastSaleDate' else  # Convert empty or unavailable dates to None\n",
    "                cell for cell, col_name in zip(row, sales_dim_columns)\n",
    "            ]\n",
    "\n",
    "            # Prepare query placeholders and execute the insert statement\n",
    "            placeholders = ', '.join(['%s'] * len(row))\n",
    "            query = f\"INSERT INTO {table_name} VALUES ({placeholders});\"\n",
    "            cursor.execute(query, row)\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d5521c9c-ba6e-4e3c-8a66-766fa0250232",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been loaded successfully into their respective schema and table\n"
     ]
    }
   ],
   "source": [
    "print('All data has been loaded successfully into their respective schema and table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f2ee2-164b-4128-917a-bedf96ed2be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
